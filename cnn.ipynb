{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jYp01vtq79P532WCd7We-41E1Ci2gQO_",
      "authorship_tag": "ABX9TyP74SQyHF+PA1/m8hNEr6Tv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philippe753/CNN_project/blob/main/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VprqOzrRUgic"
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "import gc\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, AveragePooling2D, Conv2D, MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.optimizers import SGD, Adam\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgqZRqzakxfY"
      },
      "source": [
        "# unzip celebraties images\n",
        "!unzip \"/content/drive/MyDrive/AI_dataset/img_align_celeba.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WFnDopOlsOv"
      },
      "source": [
        "# Importing data\n",
        "\n",
        "data_Y = pd.read_excel(\"/content/drive/MyDrive/AI_dataset/list_attr_celeba.xlsx\")\n",
        "data_Y_columns = data_Y.iloc[0] # This contains the name of the features of the dataframe."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ2-2Tw0gr7i",
        "outputId": "35a0f326-51f9-426f-8509-f79643f05045"
      },
      "source": [
        "# Inspecting Data\n",
        "\n",
        "# plot of the first 5 columns of the raw data\n",
        "print(data_Y.head(5))\n",
        "\n",
        "# Deleating the first row, since it contains it just a interger refereing to the total number of imgs.\n",
        "first_row = data_Y.iloc[0] #grab the first row for the header\n",
        "data_Y = data_Y[1:] #take the data less the header row\n",
        "data_Y.columns = first_row #set the header row as the df header\n",
        "print('New header:')\n",
        "data_Y.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       202599        Unnamed: 1  ...      Unnamed: 39 Unnamed: 40\n",
            "0           #  5_o_Clock_Shadow  ...  Wearing_Necktie       Young\n",
            "1  000001.jpg                -1  ...               -1           1\n",
            "2  000002.jpg                -1  ...               -1           1\n",
            "3  000003.jpg                -1  ...               -1           1\n",
            "4  000004.jpg                -1  ...               -1           1\n",
            "\n",
            "[5 rows x 41 columns]\n",
            "New header:\n",
            "0           # 5_o_Clock_Shadow  ... Wearing_Necktie Young\n",
            "1  000001.jpg               -1  ...              -1     1\n",
            "2  000002.jpg               -1  ...              -1     1\n",
            "3  000003.jpg               -1  ...              -1     1\n",
            "4  000004.jpg               -1  ...              -1     1\n",
            "5  000005.jpg               -1  ...              -1     1\n",
            "\n",
            "[5 rows x 41 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0REzk7zBwA1S"
      },
      "source": [
        "## Randomly pick m images to be the training set.\n",
        "Further, every image is flattened from a 3 dimmensional array to a 1-dimensional array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLn5Sx6F7nad"
      },
      "source": [
        "m = 2000  # number of examples to train the models\n",
        "train_X = np.zeros((116412, m))\n",
        "train_Y = pd.DataFrame(data=data_Y_columns, columns=data_Y_columns)\n",
        "rand_num = np.random.randint(0,200000, m)  # random numbers to select the training set.\n",
        "img_path = np.sort(glob.glob(\"img_align_celeba/*.*\"))\n",
        "\n",
        "for i in range(0, m):\n",
        "    img = cv2.imread(img_path[rand_num[i]])\n",
        "    # flat image into an array.\n",
        "    img_v = img.reshape((img.shape[0] * img.shape[1] * img.shape[2], 1))\n",
        "    train_X[:, i] = img_v[:, 0]\n",
        "    # find the equivalent samples in data_Y.\n",
        "    train_Y = pd.concat([train_Y, data_Y[data_Y['#'] == data_Y.iloc[rand_num[i]][0]]], ignore_index=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEw292JDxqwA"
      },
      "source": [
        "# Visualizing the training set.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLdsao4TWf04"
      },
      "source": [
        "# Implementing a 1 neural neural network (perceptron)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwexPh56WgJi"
      },
      "source": [
        "# Implementing a multilayer deep neural neural network (perceptron)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}