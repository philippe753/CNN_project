{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jYp01vtq79P532WCd7We-41E1Ci2gQO_",
      "authorship_tag": "ABX9TyOnYmsZL7OX1Grmrfhzhury",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philippe753/CNN_project/blob/main/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VprqOzrRUgic"
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "import gc\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, AveragePooling2D, Conv2D, MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.optimizers import SGD, Adam\n",
        "from sklearn.preprocessing import normalize\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgqZRqzakxfY"
      },
      "source": [
        "# unzip the data frame containing the celebraties images\n",
        "!unzip \"/content/drive/MyDrive/AI_dataset/img_align_celeba.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WFnDopOlsOv"
      },
      "source": [
        "# Importing data\n",
        "data_Y = pd.read_excel(\"/content/drive/MyDrive/AI_dataset/list_attr_celeba.xlsx\")\n",
        "data_Y_columns = data_Y.iloc[0] # This contains the name of the features/columns of the dataframe."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ2-2Tw0gr7i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "29543e64-c65a-4987-c844-f09de3b5e5dc"
      },
      "source": [
        "# Inspecting Data\n",
        "\n",
        "# plot of the first 5 columns of the raw data\n",
        "print(\"Raw data frame: \\n\")\n",
        "print(data_Y.head(5))\n",
        "\n",
        "\n",
        "data_Y = data_Y.replace(-1, 0) # Replace -1 for a 0.\n",
        "# Deleating the first row, since it contains it just a interger refereing to the total number of imgs.\n",
        "first_row = data_Y.iloc[0] #grab the first row for the header\n",
        "data_Y = data_Y[1:] #take the data less the header row\n",
        "data_Y.columns = first_row #set the header row as the df header\n",
        "print('New data frame: \\n')\n",
        "data_Y.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw data frame: \n",
            "\n",
            "       202599        Unnamed: 1  ...      Unnamed: 39 Unnamed: 40\n",
            "0           #  5_o_Clock_Shadow  ...  Wearing_Necktie       Young\n",
            "1  000001.jpg                -1  ...               -1           1\n",
            "2  000002.jpg                -1  ...               -1           1\n",
            "3  000003.jpg                -1  ...               -1           1\n",
            "4  000004.jpg                -1  ...               -1           1\n",
            "\n",
            "[5 rows x 41 columns]\n",
            "New data frame: \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#</th>\n",
              "      <th>5_o_Clock_Shadow</th>\n",
              "      <th>Arched_Eyebrows</th>\n",
              "      <th>Attractive</th>\n",
              "      <th>Bags_Under_Eyes</th>\n",
              "      <th>Bald</th>\n",
              "      <th>Bangs</th>\n",
              "      <th>Big_Lips</th>\n",
              "      <th>Big_Nose</th>\n",
              "      <th>Black_Hair</th>\n",
              "      <th>Blond_Hair</th>\n",
              "      <th>Blurry</th>\n",
              "      <th>Brown_Hair</th>\n",
              "      <th>Bushy_Eyebrows</th>\n",
              "      <th>Chubby</th>\n",
              "      <th>Double_Chin</th>\n",
              "      <th>Eyeglasses</th>\n",
              "      <th>Goatee</th>\n",
              "      <th>Gray_Hair</th>\n",
              "      <th>Heavy_Makeup</th>\n",
              "      <th>High_Cheekbones</th>\n",
              "      <th>Male</th>\n",
              "      <th>Mouth_Slightly_Open</th>\n",
              "      <th>Mustache</th>\n",
              "      <th>Narrow_Eyes</th>\n",
              "      <th>No_Beard</th>\n",
              "      <th>Oval_Face</th>\n",
              "      <th>Pale_Skin</th>\n",
              "      <th>Pointy_Nose</th>\n",
              "      <th>Receding_Hairline</th>\n",
              "      <th>Rosy_Cheeks</th>\n",
              "      <th>Sideburns</th>\n",
              "      <th>Smiling</th>\n",
              "      <th>Straight_Hair</th>\n",
              "      <th>Wavy_Hair</th>\n",
              "      <th>Wearing_Earrings</th>\n",
              "      <th>Wearing_Hat</th>\n",
              "      <th>Wearing_Lipstick</th>\n",
              "      <th>Wearing_Necklace</th>\n",
              "      <th>Wearing_Necktie</th>\n",
              "      <th>Young</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0           # 5_o_Clock_Shadow  ... Wearing_Necktie Young\n",
              "1  000001.jpg                0  ...               0     1\n",
              "2  000002.jpg                0  ...               0     1\n",
              "3  000003.jpg                0  ...               0     1\n",
              "4  000004.jpg                0  ...               0     1\n",
              "5  000005.jpg                0  ...               0     1\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvvf3TVmKvmR"
      },
      "source": [
        "## Description of our data Frame\n",
        "As we can see bellow, most examples are not bold, do not have Clock shadow, do not have bangs, do not have blond hair, do not have double chin, do not have eyeglasses, do not have a Goatee, nor gray_hair, nor mustache, nor male skin, nor have a recending hairline, nor have rosy cheeks,nor side burns, nor wearing a hat, nor wearing a necktie.\n",
        "\n",
        "The first model we'll learn is a  simple logisitc neural network to try to predict attrative and non attrative people. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "PuvWBriyMii8",
        "outputId": "c0f6c302-0d9c-4bef-8f46-c848e08abfed"
      },
      "source": [
        "data_Y.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#</th>\n",
              "      <th>5_o_Clock_Shadow</th>\n",
              "      <th>Arched_Eyebrows</th>\n",
              "      <th>Attractive</th>\n",
              "      <th>Bags_Under_Eyes</th>\n",
              "      <th>Bald</th>\n",
              "      <th>Bangs</th>\n",
              "      <th>Big_Lips</th>\n",
              "      <th>Big_Nose</th>\n",
              "      <th>Black_Hair</th>\n",
              "      <th>Blond_Hair</th>\n",
              "      <th>Blurry</th>\n",
              "      <th>Brown_Hair</th>\n",
              "      <th>Bushy_Eyebrows</th>\n",
              "      <th>Chubby</th>\n",
              "      <th>Double_Chin</th>\n",
              "      <th>Eyeglasses</th>\n",
              "      <th>Goatee</th>\n",
              "      <th>Gray_Hair</th>\n",
              "      <th>Heavy_Makeup</th>\n",
              "      <th>High_Cheekbones</th>\n",
              "      <th>Male</th>\n",
              "      <th>Mouth_Slightly_Open</th>\n",
              "      <th>Mustache</th>\n",
              "      <th>Narrow_Eyes</th>\n",
              "      <th>No_Beard</th>\n",
              "      <th>Oval_Face</th>\n",
              "      <th>Pale_Skin</th>\n",
              "      <th>Pointy_Nose</th>\n",
              "      <th>Receding_Hairline</th>\n",
              "      <th>Rosy_Cheeks</th>\n",
              "      <th>Sideburns</th>\n",
              "      <th>Smiling</th>\n",
              "      <th>Straight_Hair</th>\n",
              "      <th>Wavy_Hair</th>\n",
              "      <th>Wearing_Earrings</th>\n",
              "      <th>Wearing_Hat</th>\n",
              "      <th>Wearing_Lipstick</th>\n",
              "      <th>Wearing_Necklace</th>\n",
              "      <th>Wearing_Necktie</th>\n",
              "      <th>Young</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "      <td>202599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>202599</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>158328.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>180083</td>\n",
              "      <td>148509</td>\n",
              "      <td>103833</td>\n",
              "      <td>161153</td>\n",
              "      <td>198052</td>\n",
              "      <td>171890</td>\n",
              "      <td>153814</td>\n",
              "      <td>155083</td>\n",
              "      <td>154127</td>\n",
              "      <td>172616</td>\n",
              "      <td>192287</td>\n",
              "      <td>161027</td>\n",
              "      <td>173796</td>\n",
              "      <td>190936</td>\n",
              "      <td>193140</td>\n",
              "      <td>189406</td>\n",
              "      <td>189883</td>\n",
              "      <td>194100</td>\n",
              "      <td>124209</td>\n",
              "      <td>110410</td>\n",
              "      <td>118165</td>\n",
              "      <td>104657</td>\n",
              "      <td>194182</td>\n",
              "      <td>179270</td>\n",
              "      <td>169158</td>\n",
              "      <td>145032</td>\n",
              "      <td>193898</td>\n",
              "      <td>146389</td>\n",
              "      <td>186436</td>\n",
              "      <td>189284</td>\n",
              "      <td>191150</td>\n",
              "      <td>104930</td>\n",
              "      <td>160377</td>\n",
              "      <td>137855</td>\n",
              "      <td>164323</td>\n",
              "      <td>192781</td>\n",
              "      <td>106884</td>\n",
              "      <td>177686</td>\n",
              "      <td>187867</td>\n",
              "      <td>156734</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0                #  5_o_Clock_Shadow  ...  Wearing_Necktie   Young\n",
              "count       202599            202599  ...           202599  202599\n",
              "unique      202599                 2  ...                2       2\n",
              "top     158328.jpg                 0  ...                0       1\n",
              "freq             1            180083  ...           187867  156734\n",
              "\n",
              "[4 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0REzk7zBwA1S"
      },
      "source": [
        "## Randomly pick m images to be the training set.\n",
        "Every image is flattened from a 3 dimmensional array to a 1-dimensional array and then standarized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLn5Sx6F7nad"
      },
      "source": [
        "m = 2000  # number of examples to train the models\n",
        "num_features = 116412 # num of features for each image\n",
        "train_X = np.zeros((num_features, m))\n",
        "train_Y = pd.DataFrame(data=data_Y_columns, columns=data_Y_columns)\n",
        "# random numbers to selecet the training examples from the data frame.\n",
        "rand_num = np.random.choice(range(202599), m, replace=False) \n",
        "img_path = np.sort(glob.glob(\"img_align_celeba/*.*\"))\n",
        "\n",
        "for i in range(0, m):\n",
        "    img = cv2.imread(img_path[rand_num[i]])\n",
        "    # flat image into an array.\n",
        "    img_v = img.reshape((img.shape[0] * img.shape[1] * img.shape[2], 1))\n",
        "    train_X[:, i] = img_v[:, 0]\n",
        "    # find the equivalent samples in data_Y.\n",
        "    train_Y = pd.concat([train_Y, data_Y[data_Y['#'] == data_Y.iloc[rand_num[i]][0]]], ignore_index=True)\n",
        "\n",
        "# Standardize data\n",
        "train_X = train_X / 255.\n",
        "\n",
        "# For now, we are only interested on the attribute attractive.\n",
        "train_Y_attractive = train_Y['Attractive']\n",
        "train_Y_attractive = train_Y_attractive.values.reshape((1, -1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "HEw292JDxqwA",
        "outputId": "4e1bbeb7-1028-4138-e95c-8b576fc30800"
      },
      "source": [
        "## Visualizing the training set. \n",
        "# Note that since our models were randomly chosen from the data frame, then this\n",
        "# sample should be a good representation of the Data Frame.\n",
        "print(\"train_X shape is: \" + str(train_X.shape))\n",
        "print(\"train_Y shape is: \" + str(train_Y.shape))\n",
        "print(\"\\nDescription of the features of the training set:\")\n",
        "train_Y.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_X shape is: (116412, 2000)\n",
            "train_Y shape is: (2000, 41)\n",
            "\n",
            "Description of the features of the training set:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#</th>\n",
              "      <th>5_o_Clock_Shadow</th>\n",
              "      <th>Arched_Eyebrows</th>\n",
              "      <th>Attractive</th>\n",
              "      <th>Bags_Under_Eyes</th>\n",
              "      <th>Bald</th>\n",
              "      <th>Bangs</th>\n",
              "      <th>Big_Lips</th>\n",
              "      <th>Big_Nose</th>\n",
              "      <th>Black_Hair</th>\n",
              "      <th>Blond_Hair</th>\n",
              "      <th>Blurry</th>\n",
              "      <th>Brown_Hair</th>\n",
              "      <th>Bushy_Eyebrows</th>\n",
              "      <th>Chubby</th>\n",
              "      <th>Double_Chin</th>\n",
              "      <th>Eyeglasses</th>\n",
              "      <th>Goatee</th>\n",
              "      <th>Gray_Hair</th>\n",
              "      <th>Heavy_Makeup</th>\n",
              "      <th>High_Cheekbones</th>\n",
              "      <th>Male</th>\n",
              "      <th>Mouth_Slightly_Open</th>\n",
              "      <th>Mustache</th>\n",
              "      <th>Narrow_Eyes</th>\n",
              "      <th>No_Beard</th>\n",
              "      <th>Oval_Face</th>\n",
              "      <th>Pale_Skin</th>\n",
              "      <th>Pointy_Nose</th>\n",
              "      <th>Receding_Hairline</th>\n",
              "      <th>Rosy_Cheeks</th>\n",
              "      <th>Sideburns</th>\n",
              "      <th>Smiling</th>\n",
              "      <th>Straight_Hair</th>\n",
              "      <th>Wavy_Hair</th>\n",
              "      <th>Wearing_Earrings</th>\n",
              "      <th>Wearing_Hat</th>\n",
              "      <th>Wearing_Lipstick</th>\n",
              "      <th>Wearing_Necklace</th>\n",
              "      <th>Wearing_Necktie</th>\n",
              "      <th>Young</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>151433.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>1786</td>\n",
              "      <td>1476</td>\n",
              "      <td>1009</td>\n",
              "      <td>1601</td>\n",
              "      <td>1948</td>\n",
              "      <td>1735</td>\n",
              "      <td>1510</td>\n",
              "      <td>1546</td>\n",
              "      <td>1522</td>\n",
              "      <td>1697</td>\n",
              "      <td>1888</td>\n",
              "      <td>1573</td>\n",
              "      <td>1710</td>\n",
              "      <td>1884</td>\n",
              "      <td>1898</td>\n",
              "      <td>1870</td>\n",
              "      <td>1865</td>\n",
              "      <td>1906</td>\n",
              "      <td>1230</td>\n",
              "      <td>1088</td>\n",
              "      <td>1142</td>\n",
              "      <td>1013</td>\n",
              "      <td>1905</td>\n",
              "      <td>1728</td>\n",
              "      <td>1670</td>\n",
              "      <td>1447</td>\n",
              "      <td>1921</td>\n",
              "      <td>1445</td>\n",
              "      <td>1831</td>\n",
              "      <td>1875</td>\n",
              "      <td>1884</td>\n",
              "      <td>1018</td>\n",
              "      <td>1605</td>\n",
              "      <td>1346</td>\n",
              "      <td>1627</td>\n",
              "      <td>1891</td>\n",
              "      <td>1083</td>\n",
              "      <td>1772</td>\n",
              "      <td>1828</td>\n",
              "      <td>1540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0                #  5_o_Clock_Shadow  ...  Wearing_Necktie  Young\n",
              "count         2000              2000  ...             2000   2000\n",
              "unique        2000                 2  ...                2      2\n",
              "top     151433.jpg                 0  ...                0      1\n",
              "freq             1              1786  ...             1828   1540\n",
              "\n",
              "[4 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lopLdQovblgS"
      },
      "source": [
        "## Perceptron model to predict attractive and non-attractive people.\n",
        "\n",
        "We will implement the most basic implementation of a neural network to see how good a single layer neural network can accurately predict if a person is attractive or not. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLdsao4TWf04"
      },
      "source": [
        "# Implementing a 2 layer neural network\n",
        "\n",
        "class TwoLayerNN:\n",
        "\n",
        "    def __init__(self, learning_rate=0.01, num_ite=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_ite = num_ite\n",
        "        self.num_x = num_features\n",
        "        self.num_hidden = 20\n",
        "        self.num_y = 1 # number of output units.\n",
        "        self.W1 = None\n",
        "        self.b1 = None\n",
        "        self.W2 = None\n",
        "        self.b2 = None\n",
        "\n",
        "    def initialize_parameters(self, num_x, num_hidden, num_y):\n",
        "        self.W1 = np.random.randn(num_hidden, num_x) * 0.01\n",
        "        self.b1 = np.zeros((num_hidden, 1))\n",
        "        self.W2 = np.random.randn(num_y, num_hidden) * 0.01\n",
        "        self.b2 = np.zeros((num_hidden, 1))\n",
        "        parameters = {\"W1\": self.W1, \"b1\": self.b1, \"W2\": self.W2, \"b2\": self.b2}\n",
        "        return parameters\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        grads = {}\n",
        "        costs = []                              # to keep track of the cost\n",
        "        # Initialize parameters\n",
        "        parameters = self.initialize_parameters(self.num_x, self.num_hidden, self.num_y)\n",
        "        for i in range(0, self.num_ite):\n",
        "            # Forward propagation: with a relu and then sigmoid activation function\n",
        "            A1, cache1 = self.linear_activation_forward(X, self.W1, self.b1, \"relu\")\n",
        "            A2, cache2 = self.linear_activation_forward(A1, self.W2, self.b2, \"sigmoid\")\n",
        "\n",
        "            # Cost function\n",
        "            cost  = self.compute_cost(A2, Y)\n",
        "\n",
        "            # Initializing backward propagation\n",
        "            dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
        "            dA1, dW2, db2 = self.linear_activation_backward(dA2, cache2, \"sigmoid\")\n",
        "            A0, dW1, db1 = self.linear_activation_backward(dA1, cache1, \"relu\")\n",
        "            grads['dW1'] = dW1\n",
        "            grads['db1'] = db1\n",
        "            grads['dW2'] = dW2\n",
        "            grads['db2'] = db2\n",
        "\n",
        "            # Update the paramters.\n",
        "            parameters = self.update_parameters(parameters, grads)\n",
        "            self.W1 = parameters[\"W1\"]\n",
        "            self.b1 = parameters[\"b1\"]\n",
        "            self.W2 = parameters[\"W2\"]\n",
        "            self.b2 = parameters[\"b2\"]\n",
        "\n",
        "    def linear_forward(self, A, W, b):\n",
        "        # Implement the linear part of a layer's forward propagation.\n",
        "        Z = np.dot(W, A) + b\n",
        "        cache = (A, W, b)\n",
        "        return Z, cache\n",
        "\n",
        "    def linear_activation_forward(self, A_prev, W, b, activation):\n",
        "        # Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
        "        Z, linear_cache = self.linear_forward(A_prev, W, b)\n",
        "        if activation == \"sigmoid\":\n",
        "            A = 1/(1 + np.exp(Z))\n",
        "        elif activation == \"relu\":\n",
        "            A = np.maximum(Z, 0)\n",
        "        cache = (linear_cache, Z)  # note th\n",
        "        return A, cache\n",
        "\n",
        "    def linear_backward(self, dZ, cache):\n",
        "        # linear backword propagation\n",
        "        A_prev, W, b = cache\n",
        "        m = A_prev.shape[1]\n",
        "\n",
        "        dW = (1/m) * np.dot(dZ, A_prev.T)\n",
        "        db = (1/m) * np.sum(dZ, axis = 1, keepdims=True)\n",
        "        print('dz: ' + str(dZ.shape))\n",
        "        print('W.T: ' + str(W.T.shape))\n",
        "        dA_prev = np.dot(W.T, dZ)\n",
        "\n",
        "    def linear_activation_backward(self, dA, cache, activation):\n",
        "        # Backward propagation.\n",
        "        linear_cache, activation_cache = cache\n",
        "        Z = activation_cache\n",
        "        if activation == \"relu\":\n",
        "          # Implement Back propagation witha relu activation function\n",
        "            dZ = self.relu_backward(dA, activation_cache)\n",
        "            dA_prev, dW, db = self.linear_backward(dZ, linear_cache)\n",
        "        elif activation == \"sigmoid\":\n",
        "          # Implement Back propagation witha sigmoid activation function\n",
        "            dsig = 1/(1+np.exp(-Z)) * (1 - 1/(1+np.exp(-Z)))\n",
        "            dZ = dA * dsig    #= self.sigmoid_backward(dA, activation_cache)\n",
        "            dA_prev, dW, db = self.linear_backward(dZ, linear_cache)\n",
        "        return dA_prev, dW, db\n",
        "\n",
        "    def compute_cost(self, AL, Y):\n",
        "        cost = -(1/m) * (np.dot(Y, np.log(AL).T) + np.dot((1 - Y), np.log(1-AL).T))\n",
        "\n",
        "    def update_parameters(self, parameters, grads):\n",
        "        # Update the weiths and bieses of each layer\n",
        "        parameters = params.copy()\n",
        "        L = len(parameters) // 2\n",
        "        for l in range(L):\n",
        "            parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - self.learning_rate * grads[\"dW\" + str(l+1)]\n",
        "            parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - self.learning_rate * grads[\"db\" + str(l+1)]\n",
        "        return parameters\n",
        "\n",
        "    def prediction(self, X):\n",
        "        Z_1 = self.linear_activation_forward(X, self.W1, self.b1, \"relu\")\n",
        "        A2, cache2 = self.linear_activation_forward(A1, self.W2, self.b2, \"sigmoid\")\n",
        "        y_predict = A2\n",
        "        # The unit step activation function returns only 1 or 0.\n",
        "        return y_predict\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "-rA-n1ayqdvr",
        "outputId": "75be3d30-e6fa-4333-e8f2-481c39435004"
      },
      "source": [
        "# Train neural network\n",
        "#print(\"train_Y_Attractive shape: \" + str(train_Y_attractive.shape))\n",
        "\n",
        "my_nn = TwoLayerNN(learning_rate=0.01, num_ite=1000)\n",
        "my_nn.fit(train_X, train_Y_attractive)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "dz: (20, 2000)\n",
            "W.T: (20, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-07c4391b4308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmy_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwoLayerNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmy_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y_attractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-60-549ccb99440e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Initializing backward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mdA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mdA1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_activation_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mA0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_activation_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dW1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdW1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-549ccb99440e>\u001b[0m in \u001b[0;36mlinear_activation_backward\u001b[0;34m(self, dA, cache, activation)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mdsig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdsig\u001b[0m    \u001b[0;31m#= self.sigmoid_backward(dA, activation_cache)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mdA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-549ccb99440e>\u001b[0m in \u001b[0;36mlinear_backward\u001b[0;34m(self, dZ, cache)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dz: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W.T: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mdA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlinear_activation_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (20,1) and (20,2000) not aligned: 1 (dim 1) != 20 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "cp9gDq1u1Mmd",
        "outputId": "b7b5600b-06f3-4d89-d08f-7c4dd3bf15be"
      },
      "source": [
        "fit(train_X, train_Y_):"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4faa7fb2311b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    fit(train_X, train_Y_Attractive):\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwexPh56WgJi"
      },
      "source": [
        "# Implementing a 2 layer neural network\n",
        "\n",
        "class DeepNN:\n",
        "\n",
        "    def __init__(self, learning_rate=0.01, num_ite=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_ite = num_ite\n",
        "\n",
        "    def initialize_parameters_deep(self, layer_dims):\n",
        "        parameters = {}\n",
        "        L = len(layer_dims) # number of layers in the network\n",
        "        for l in range(1, L):\n",
        "            parameters[\"W\" + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
        "            parameters[\"b\" + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "        return parameters\n",
        "\n",
        "    def fit(self, X, Y, layers_dims):\n",
        "        costs = []                              # to keep track of the cost\n",
        "        # Initialize parameters\n",
        "        parameters = self.initialize_parameters_deep(layers_dims)\n",
        "        for i in range(0, self.num_ite):\n",
        "            print(i)\n",
        "            # Forward propagation: with a relu and then sigmoid activation function\n",
        "            AL, caches = self.L_model_forward(X, parameters)\n",
        "            print('A')\n",
        "            # Cost function\n",
        "            cost  = self.compute_cost(AL, Y)\n",
        "            print('B')\n",
        "            # Initializing backward propagation\n",
        "            grads = self.L_model_backward(AL, Y, caches)\n",
        "            print('C')\n",
        "            # Update the paramters.\n",
        "            parameters = self.update_parameters(parameters, grads, self.learning_rate)\n",
        "            print('D')\n",
        "            # Print the cost every 100 iterations\n",
        "            if i % 100 == 0 or i == num_iterations - 1:\n",
        "                print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
        "            if i % 100 == 0 or i == num_iterations:\n",
        "                costs.append(cost)\n",
        "        return parameters, costs\n",
        "\n",
        "    def linear_forward(self, A, W, b):\n",
        "        # Implement the linear part of a layer's forward propagation. ( CHANGE )\n",
        "        Z = np.dot(W, A) + b\n",
        "        cache = (A, W, b)  \n",
        "        return Z, cache\n",
        "\n",
        "    def L_model_forward(self, X, parameters):\n",
        "        # Implement the linear part of a layer's forward propagation.\n",
        "        caches = []\n",
        "        A = X\n",
        "        L = len(parameters) // 2 \n",
        "        # loop every layer\n",
        "        for l in range(1, L):\n",
        "            A_prev = A \n",
        "            A, cache = self.linear_activation_forward(A_prev, parameters[\"W\" + str(l)], parameters[\"b\" + str(l)], \"relu\")\n",
        "            caches.append(cache)\n",
        "        AL, cache = self.linear_activation_forward(A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)], \"sigmoid\")\n",
        "        caches.append(cache)\n",
        "        return AL, caches\n",
        "\n",
        "    def linear_backward(self, dZ, cache):\n",
        "        # Implement the linear portion of backward propagation for a single layer ( CHANGE )\n",
        "        A_prev, W, b = cache\n",
        "        m = A_prev.shape[1]\n",
        "        #print('m: ' + str(m))\n",
        "        #print('linear_backward A')\n",
        "        print('dZ: ' + str(dZ.shape))\n",
        "        #print('dZ: ' + str(dZ))\n",
        "        print('A_prev.T: ' + str(A_prev.T.shape))\n",
        "        #print('A_prev.T: ' + str(A_prev.T))\n",
        "        dW = (1/m) * np.dot(dZ, A_prev.T)\n",
        "        db = (1/m) * np.sum(dZ, axis = 1, keepdims=True)\n",
        "        print('YES')\n",
        "        dA_prev = np.dot(W.T, dZ)\n",
        "        print('YES, YES')\n",
        "        \n",
        "        return dA_prev, dW, db\n",
        "\n",
        "\n",
        "    def L_model_backward(self, AL, Y, caches):\n",
        "        grads = {}\n",
        "        L = len(caches) # the number of layers\n",
        "        m = AL.shape[1]\n",
        "        Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "        dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "        current_cache = caches[L-1]\n",
        "        print(\"B1\")\n",
        "        dA_prev_temp, dW_temp, db_temp = self.linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
        "        print(\"B2\")\n",
        "        grads[\"dA\" + str(L-1)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(L)] = dW_temp\n",
        "        grads[\"db\" + str(L)] = db_temp\n",
        "        for l in reversed(range(L-1)):\n",
        "            print(\"B3\")\n",
        "            print('l = ' + str(l))\n",
        "            current_cache = caches[l]\n",
        "            dA_prev_temp, dW_temp, db_temp = self.linear_activation_backward(dA_prev_temp, current_cache, \"relu\")\n",
        "            grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "            grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "            grads[\"db\" + str(l + 1)] = db_temp\n",
        "            print(\"b4\")\n",
        "        return grads\n",
        "\n",
        "    def linear_activation_forward(self, A_prev, W, b, activation):\n",
        "        # Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
        "        Z, linear_cache = self.linear_forward(A_prev, W, b)\n",
        "        if activation == \"sigmoid\":\n",
        "            A = 1/(1 + np.exp(Z))\n",
        "        elif activation == \"relu\":\n",
        "            A = np.maximum(Z, 0)\n",
        "        cache = (linear_cache, Z)  # note th\n",
        "        return A, cache\n",
        "\n",
        "    def linear_activation_backward(self, dA, cache, activation):\n",
        "        # Backward propagation.\n",
        "        linear_cache, activation_cache = cache\n",
        "        Z = activation_cache\n",
        "        if activation == \"relu\":\n",
        "          # Implement Back propagation witha relu activation function\n",
        "            print('relu bitches')\n",
        "            dsig = np.where(Z>0, 1, 0)\n",
        "            print('dA: ' + str(dA.shape))\n",
        "            print('dsig: ' + str(dsig.shape))\n",
        "            dZ = dA * dsig\n",
        "            print('dZ: ' + str(dZ.shape))\n",
        "            dA_prev, dW, db = self.linear_backward(dZ, linear_cache)\n",
        "            print('im out')\n",
        "        elif activation == \"sigmoid\":\n",
        "            print('sigmoid bitches')\n",
        "          # Implement Back propagation witha sigmoid activation function\n",
        "            dsig = 1/(1+np.exp(-Z)) * (1 - 1/(1+np.exp(-Z)))\n",
        "            print('sigmoid dsig: ' + str(dsig.shape))\n",
        "            print('sigmoid dA: ' + str(dA.shape))\n",
        "            print('sigmoid dsig: ' + str(dsig.shape))\n",
        "            dZ = dA * dsig    #= self.sigmoid_backward(dA, activation_cache)\n",
        "            print('sigmoid dZ: ' + str(dZ.shape))\n",
        "            dA_prev, dW, db = self.linear_backward(dZ, linear_cache)\n",
        "        return dA_prev, dW, db\n",
        "\n",
        "    def compute_cost(self, AL, Y):\n",
        "        cost = -(1/m) * (np.dot(Y, np.log(AL).T) + np.dot((1 - Y), np.log(1-AL).T))\n",
        "\n",
        "    def update_parameters(self, params, grads, learning_rate):\n",
        "        # Update the weiths and bieses of each layer\n",
        "        parameters = params.copy()\n",
        "        L = len(parameters) // 2\n",
        "        for l in range(L):\n",
        "            parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
        "            parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
        "        return parameters\n",
        "\n",
        "    def prediction(self, X):\n",
        "        Z_1 = self.linear_activation_forward(X, self.W1, self.b1, \"relu\")\n",
        "        A2, cache2 = self.linear_activation_forward(A1, self.W2, self.b2, \"sigmoid\")\n",
        "        y_predict = A2\n",
        "        # The unit step activation function returns only 1 or 0.\n",
        "        return y_predict\n",
        "\n",
        "      "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p8dbgmZVnnI",
        "outputId": "e13be6fd-9c81-4743-8567-b8fd9e312fc3"
      },
      "source": [
        "layers_dims = [116412, 20, 7, 5, 1]\n",
        "              \n",
        "my_deepNN = DeepNN(learning_rate=0.01, num_ite=100)\n",
        "parameters, costs = my_deepNN.fit(train_X, train_Y_attractive, layers_dims)\n",
        "#parameters, costs = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "A\n",
            "B\n",
            "B1\n",
            "sigmoid bitches\n",
            "sigmoid dsig: (1, 2000)\n",
            "sigmoid dA: (1, 2000)\n",
            "sigmoid dsig: (1, 2000)\n",
            "sigmoid dZ: (1, 2000)\n",
            "dZ: (1, 2000)\n",
            "A_prev.T: (2000, 5)\n",
            "YES\n",
            "YES, YES\n",
            "B2\n",
            "B3\n",
            "l = 2\n",
            "relu bitches\n",
            "dA: (5, 2000)\n",
            "dsig: (5, 2000)\n",
            "dZ: (5, 2000)\n",
            "dZ: (5, 2000)\n",
            "A_prev.T: (2000, 7)\n",
            "YES\n",
            "YES, YES\n",
            "im out\n",
            "b4\n",
            "B3\n",
            "l = 1\n",
            "relu bitches\n",
            "dA: (7, 2000)\n",
            "dsig: (7, 2000)\n",
            "dZ: (7, 2000)\n",
            "dZ: (7, 2000)\n",
            "A_prev.T: (2000, 20)\n",
            "YES\n",
            "YES, YES\n",
            "im out\n",
            "b4\n",
            "B3\n",
            "l = 0\n",
            "relu bitches\n",
            "dA: (20, 2000)\n",
            "dsig: (20, 2000)\n",
            "dZ: (20, 2000)\n",
            "dZ: (20, 2000)\n",
            "A_prev.T: (2000, 116412)\n",
            "YES\n",
            "YES, YES\n",
            "im out\n",
            "b4\n",
            "C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meoL3C6W4ZJE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}